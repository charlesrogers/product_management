# Concept & Solution Validation
## Timeline to
1. Discover objectives and the user's current satisfaction
2. For unmet objectives, determine what would meet their needs
3. Generate a solution that meets the unmet needs
a. Focus less on the tradeoffs & real-world implications of the solution (only to the degree it is required to make the solution believable to the potential user (price, et al) and more on which things you believe that would sufficiently solve their problems
4. Verbal Prototype
5. Survey Demand Test
6. High-fidelity Prototype
## Process
Verbal & Initial Prototype
1. Measure the importance of the objective the problem is designed to solve
2. Measure the satisfaction with  current solutions
3. Test concepts with those where there is an opportunity to improve their process
a. Perhaps: 4-5 Importance, 1-4 Satisfaction, IMP > SAT
4. Determine where they are in the search process:
a. Don't feel pain
ⅰ. As mentioned above, it's possible to control for this as we're previously asking people about Importance and Satisfaction and we can just filter by those for whom there is opportunity for improvement.
b. Not yet looking for a solution
c. Passive looking - I.e. they know it is a problem and are open to solutions for that problem
d. Active looking
e. Deciding
f. Recently purchased
5. Present the  concept in a succinct manner
a. At the product level - for example: How likely you are to adopt:
1. An online tool that allows you to monitor all your orders and their status in one place
2. A service that provides suppliers who can dual source your existing products
b. At the feature level (aka Alexa style) - for example: How  likely would you be to adopt (an online tool) that:
ⅰ. Includes  all the features you indicated were important (i.e you rated a 3, 4, or 5).
ⅱ. @Lytle, Alexa(alexa.lytle) Could you post a screenshot of your survey here?
## High-fidelity Prototype
1. Wireframes et al
## General Guidelines
• Only test with people who have  the problem (or should have—understanding why they don't is helpful to understand to whom the solutions apply)
Open Questions
Do we ask about things are the feature or product level?
To Be Incorporated
1. Predictive
a. Real world
b. 
2. Noise/discount rate
3. Measurement
a. Understand
b. Desire
c. Quality
4. Conversion rate
a. 
5. Retention rate
a. 
6. How likely they are to use
a. 
7. Why
8. Who

--- TO MERGE:
---
# Evaluative Research
## Establish Success Metrics
• What should be different about the world after this feature is released?
• Determine how would you detect that?
## Hierarchal Model of Feature Evaluation
Evaluating the feature should result in identifying the core risks in failure, specifically why—this model identifies where the is a lack of fit between the user's world and the feature we designing to help them make progress toward their goals.
1. Useful: User objectives should be identified and their relevance should be confirmed with the user during the test; if the objective is not either "Very" or "Extremely important", they likely are not a relevant test participant for this feature (and if they don't say it is at least "moderately important", their results should probably be discarded).
a. Confirm that the objective is important to them:
ⅰ. Option A: Explicit 
1. Explicitly ask their importance & satisfaction (Likert Scale): On a scale of 1-5, 1 being "Not at all important, 5 being extremely important", how important is it that you are able to..."
a. This is often hard for people to answer the first few times, so it takes a bit of coaxing/patience/making them feel comfortable first.
2. Calculate a rough opportunity score (Imp + (Imp - Sat))
ⅱ. Option B: Frequency x Impact (this takes a long time and can be hard to compare across objectives)
1. Frequency - How often does this objective come up
2. Impact - Magnitude of consequences
a. Time spent
b. Money spent/lost
c. Frustration
d. Damage to reputation
ⅲ. Option 3: Qualitative evaluation
1. Measure their energy/vibe
2. This is the most subjective
2. Discoverable
a. Time to discover [measured in seconds]
b. Do they recognize that this feature can help them achieve their objective
3. Understandable
4. Believable [Typically relevant for data]
5. Objection-Functionality Match
a. Potential Satisfaction - does this enable them to do what they were trying to do [1-5 - valuable/enablement]
b. Difficulty/Cognitive load/Ease of Use [1-5]
c. Time to complete [measured in seconds]
6. Functional [Post-release performance measurement]
7. Predict Success of Feature [For internal use only]
a. CR Metrics
ⅰ. 
b. Potential weaknesses
Sample
Count
Stage
Objective
Relevant Criteria
Notes
Dan
Lincon
Marwhan
Adam
Vincent
Importance
Current
New
Importance
Current
New
Importance
Current
New
Importance
Current
New App
New PC
Importance
Current
New
1
Sending the initial message
Minimize the time to determine how to send the supplier a message
Knows where to click to send a message to find out if the supplier can make the specific product I have in mind
This was not a problem with these buyers because they are all experienced and have made at least one order. The message pop-up module and PDP CTA were clear.
1
4
-
4
4
4
1
4
4
1
4
4
4
2
4
4
2
Knows where to click to Find out the rough price
See Above
1
4
-
4
4
4
1
4
4
1
4
4
4
2
4
4
3
Minimize the time to get a reply from the supplier
Buyer understands the difference between chat and inquiry
There is no functional difference in inquiry and chat, but some buyers will have vestigal confusion based on previous UI
2
4
3
4
4
4
1
4
4
2
4
4
3
3
4
-
4
Minimize time to determine if the supplier is currently online
The "Chat Immediately" button caused some confustion - users would only expect to see it as an option if the supplier is currently online.
2
4
2
3
4
2
2
4
1
2
4
2
2
2
4
-
5
Minimize the time to compose initial message
Minimize the time to decide what to ask in the first message
Not an issue.
2
4
4
3
4
4
2
4
4
2
4
4
4
2
4
4
6
Minimize time to send the initial message to the desired suppliers
Minimize the time to send the same inquiry to multiple, specific suppliers
This was not an issue with these buyers. None of them used the template function.
3
4
4
4
3
3
2
3
3
2
4
4
4
3
4
4
7
Managing corresponendence over the life of a project
Minimize the time to identify messages that require action
Minimize the time to find unread messages[#16 is likley the primary issue with this objective]
3
4
4
4
4
4
3
3
3
3
4
4
4
4
4
8
Minimize the time to identify messages that require follow up
Minimize number of messages to which you want answers to which you forget about
1
1
-
-
-
9
Minimize the time to compare suppliers
Minimize the time to track evaluation of different suppliers
3
2
2
5
3
3
3
2
1
4
2
1
1
4
3
3
10
Minimize the time to compare the different salient factors between suppliers
4
3
2
4
4
4
4
3
2
4
2
1
1
11
Minimize the time to find a thread from a specific supplier
Minimize the time to identify supplier by salesperson name
5
1
1
5
3
3
4
2
1
4
2
1
1
4
4
4
12
Minimize the time to identify supplier by product image
5
4
1
4
2
1
5
3
1
4
4
1
1
3
2
1
13
Minimize the time to identify supplier by product name
5
4
1
3
3
1
3
1
1
4
3
1
1
3
2
1
14
Minimize the time to identify who the sender of message
4
3
1
5
4
3
5
2
1
5
2
1
1
4
2
2
15
Minimize the time to find messages from all suppliers about a specific project
4
4
1
5
4
3
4
2
1
5
3
1
1
4
2
2
16
Minimize the number of notifications I get from suppliers not relevant at this stage of the product
Minimize the time to distinguish between messages from suppliers with whom I'm still working and those i have decided not to work with
4
1
1
4
2
2
5
1
1
4
1
1
1
5
3
3
17
Prevent suppliers from contacting me afterwards
1
1
2
2
18
Minimize the time to end a conversation with a supplier I am not interested in working with
3
1
1
2
3
3
2
1
1
1
2
2
2
2
4
4
19
Stop communicating with suppliers I do not want to do business with.
1
1
3
3
--- 
# Optimal Usability Testing, a musing by Charles Rogers
Usability testing cannot be meaningfully completed until we understand the criteria by which we should be measuring the designs (which criteria is revealed in qualitative interviews)
1. Define Objective
a. Usability testing is great at some things, but dangerous in other cases. Here is a working theory of when it is right vs when it could lead down the wrong path, and they’re based on what has already been validated.
b. The following are the general idea (sure, it can be done in other ways, but this mitigates a lot of the risk)
ⅰ. Buyer Objective
1. Do a material amount of users want to accomplish the proposed solution
a. This is the hardest thing to determine
ⅱ. Functionality
1. This one is the second hardest thing to determine, because it requires looking at user who has actually has/has recently had this objective AND ideally uses historical data to validate the specific steps in their process.
a. The challenge here is that users are good at imagining some case that isn’t there’s for which the feature would work (perhaps out of a desire to be helpful) and will speak favorably, but they would not actually use the feature in the wild.
2. Must understand the things that need to happen AND the order the can and must happen in
a. For example, if some data isn’t available later in the process, the interface would not work, but it’s hard to establish that without spending a lot of time building a timeline first.
ⅲ. Polishing: Comprehensibility and efficacy
1. This is traditional usability as understood by most people
a. Ideally tests with a range of users
ⅰ. New users to make sure it is comprehensible to most people
ⅱ. Experienced users to make sure it isn’t too slow or cumbersome for them.
2. Usability Test Plan Template
a. Define feature
ⅰ. What does the feature do?
ⅱ. What is the KPI?
b. Define user needs this feature purportedly solves
c. Specifically enumerate the hypotheses
ⅰ. Hypothesis 1: The user wants to accomplish z objective
ⅱ. Hypothesis 2: This feature will enable the user to accomplish x, which will help the user achieve y objective
ⅲ. Hypothesis 3: Users in x situation have high demand to make progress in y vector
d. Study design
ⅰ. Discover/Verify User Objectives
1. Identify the user’s objectives related to the feature in question
a. Tell me about the last time…
b. What have you tried in the past to remedy the situation?
ⅱ. Measure Importance(Demand)
1. Measure the absolute and relative importance of those objectives
a. How important is...
b. How satisfied are you with your ability to…
3. Criteria for test participants
a. The participants should be those with the highest likelihood of sharing the purported user objectives the feature purportedly solves
4. Sample usability test plan
a. User objective:
ⅰ. Buyer wants to increase ability to communicate specific details to the supplier
b. Hypotheses
ⅰ. Hypothesis 1: Sending the supplier the request in their language ALONG with the english will make it easier for the supplier to understand
ⅱ. Hypothesis 2: Providing buyer with a instant, in-app translation tool (whatever the current incarnation of the app) will indicate to the buyer's who are open to trying a real-time translation solution to act
c. Solutions
ⅰ. Proposed solution 1: Provide real-time translation tool
ⅱ. Solution 2: Whatever current product marketing exists for the tool that we are testing
d. Study design
ⅰ. Demand and Historical Research
1. Identify the user’s objectives related to the feature in question
2. 
ⅱ. Hypothesis Test 1: Determine the level of interest, success, and
ⅲ. Hypothesis Test 2:
ⅳ. 
5. Usability test findings
a. Test participants
ⅰ. N=
ⅱ. Demo info
1. Names
2. Business 
3. Platforms used
4. etc...
b. Findings
ⅰ. Product-Market Fit: Do users want this?
1. Importance of objectives to user
2. Current satisfaction with their process/current solutions (not related to the feature)
ⅱ. Problem-solution fit: If a user were to have this buyer objective, how effective is this tool in helping them solve that objective?
1. Time to complete tasks
2. 
3. Issues
a. Enumerate any ambiguities for the users
b. Measure magnitude of problem
ⅰ. Simple measurement scale
1. Non-critical issue
2. Critical issue
ⅱ. Expanded scale (WIP)
