# Concept & Solution Validation
## Timeline to
1. Discover objectives and the user's current satisfaction
2. For unmet objectives, determine what would meet their needs
3. Generate a solution that meets the unmet needs
a. Focus less on the tradeoffs & real-world implications of the solution (only to the degree it is required to make the solution believable to the potential user (price, et al) and more on which things you believe that would sufficiently solve their problems
4. Verbal Prototype
5. Survey Demand Test
6. High-fidelity Prototype
## Process
Verbal & Initial Prototype
1. Measure the importance of the objective the problem is designed to solve
2. Measure the satisfaction with  current solutions
3. Test concepts with those where there is an opportunity to improve their process
a. Perhaps: 4-5 Importance, 1-4 Satisfaction, IMP > SAT
4. Determine where they are in the search process:
a. Don't feel pain
ⅰ. As mentioned above, it's possible to control for this as we're previously asking people about Importance and Satisfaction and we can just filter by those for whom there is opportunity for improvement.
b. Not yet looking for a solution
c. Passive looking - I.e. they know it is a problem and are open to solutions for that problem
d. Active looking
e. Deciding
f. Recently purchased
5. Present the  concept in a succinct manner
a. At the product level - for example: How likely you are to adopt:
1. An online tool that allows you to monitor all your orders and their status in one place
2. A service that provides suppliers who can dual source your existing products
b. At the feature level (aka Alexa style) - for example: How  likely would you be to adopt (an online tool) that:
ⅰ. Includes  all the features you indicated were important (i.e you rated a 3, 4, or 5).
ⅱ. @Lytle, Alexa(alexa.lytle) Could you post a screenshot of your survey here?
## High-fidelity Prototype
1. Wireframes et al
## General Guidelines
• Only test with people who have  the problem (or should have—understanding why they don't is helpful to understand to whom the solutions apply)
Open Questions
Do we ask about things are the feature or product level?
To Be Incorporated
1. Predictive
a. Real world
b. 
2. Noise/discount rate
3. Measurement
a. Understand
b. Desire
c. Quality
4. Conversion rate
a. 
5. Retention rate
a. 
6. How likely they are to use
a. 
7. Why
8. Who

--- TO MERGE:
---
# Evaluative Research
## Establish Success Metrics
• What should be different about the world after this feature is released?
• Determine how would you detect that?
## Hierarchal Model of Feature Evaluation
Evaluating the feature should result in identifying the core risks in failure, specifically why—this model identifies where the is a lack of fit between the user's world and the feature we designing to help them make progress toward their goals.
1. Useful: User objectives should be identified and their relevance should be confirmed with the user during the test; if the objective is not either "Very" or "Extremely important", they likely are not a relevant test participant for this feature (and if they don't say it is at least "moderately important", their results should probably be discarded).
a. Confirm that the objective is important to them:
ⅰ. Option A: Explicit 
1. Explicitly ask their importance & satisfaction (Likert Scale): On a scale of 1-5, 1 being "Not at all important, 5 being extremely important", how important is it that you are able to..."
a. This is often hard for people to answer the first few times, so it takes a bit of coaxing/patience/making them feel comfortable first.
2. Calculate a rough opportunity score (Imp + (Imp - Sat))
ⅱ. Option B: Frequency x Impact (this takes a long time and can be hard to compare across objectives)
1. Frequency - How often does this objective come up
2. Impact - Magnitude of consequences
a. Time spent
b. Money spent/lost
c. Frustration
d. Damage to reputation
ⅲ. Option 3: Qualitative evaluation
1. Measure their energy/vibe
2. This is the most subjective
2. Discoverable
a. Time to discover [measured in seconds]
b. Do they recognize that this feature can help them achieve their objective
3. Understandable
4. Believable [Typically relevant for data]
5. Objection-Functionality Match
a. Potential Satisfaction - does this enable them to do what they were trying to do [1-5 - valuable/enablement]
b. Difficulty/Cognitive load/Ease of Use [1-5]
c. Time to complete [measured in seconds]
6. Functional [Post-release performance measurement]
7. Predict Success of Feature [For internal use only]
a. CR Metrics
ⅰ. 
b. Potential weaknesses

--- 
# Optimal Usability Testing, a musing by Charles Rogers
Usability testing cannot be meaningfully completed until we understand the criteria by which we should be measuring the designs (which criteria is revealed in qualitative interviews)
1. Define Objective
a. Usability testing is great at some things, but dangerous in other cases. Here is a working theory of when it is right vs when it could lead down the wrong path, and they’re based on what has already been validated.
b. The following are the general idea (sure, it can be done in other ways, but this mitigates a lot of the risk)
ⅰ. Buyer Objective
1. Do a material amount of users want to accomplish the proposed solution
a. This is the hardest thing to determine
ⅱ. Functionality
1. This one is the second hardest thing to determine, because it requires looking at user who has actually has/has recently had this objective AND ideally uses historical data to validate the specific steps in their process.
a. The challenge here is that users are good at imagining some case that isn’t there’s for which the feature would work (perhaps out of a desire to be helpful) and will speak favorably, but they would not actually use the feature in the wild.
2. Must understand the things that need to happen AND the order the can and must happen in
a. For example, if some data isn’t available later in the process, the interface would not work, but it’s hard to establish that without spending a lot of time building a timeline first.
ⅲ. Polishing: Comprehensibility and efficacy
1. This is traditional usability as understood by most people
a. Ideally tests with a range of users
ⅰ. New users to make sure it is comprehensible to most people
ⅱ. Experienced users to make sure it isn’t too slow or cumbersome for them.
2. Usability Test Plan Template
a. Define feature
ⅰ. What does the feature do?
ⅱ. What is the KPI?
b. Define user needs this feature purportedly solves
c. Specifically enumerate the hypotheses
ⅰ. Hypothesis 1: The user wants to accomplish z objective
ⅱ. Hypothesis 2: This feature will enable the user to accomplish x, which will help the user achieve y objective
ⅲ. Hypothesis 3: Users in x situation have high demand to make progress in y vector
d. Study design
ⅰ. Discover/Verify User Objectives
1. Identify the user’s objectives related to the feature in question
a. Tell me about the last time…
b. What have you tried in the past to remedy the situation?
ⅱ. Measure Importance(Demand)
1. Measure the absolute and relative importance of those objectives
a. How important is...
b. How satisfied are you with your ability to…
3. Criteria for test participants
a. The participants should be those with the highest likelihood of sharing the purported user objectives the feature purportedly solves
4. Sample usability test plan
a. User objective:
ⅰ. Buyer wants to increase ability to communicate specific details to the supplier
b. Hypotheses
ⅰ. Hypothesis 1: Sending the supplier the request in their language ALONG with the english will make it easier for the supplier to understand
ⅱ. Hypothesis 2: Providing buyer with a instant, in-app translation tool (whatever the current incarnation of the app) will indicate to the buyer's who are open to trying a real-time translation solution to act
c. Solutions
ⅰ. Proposed solution 1: Provide real-time translation tool
ⅱ. Solution 2: Whatever current product marketing exists for the tool that we are testing
d. Study design
ⅰ. Demand and Historical Research
1. Identify the user’s objectives related to the feature in question
2. 
ⅱ. Hypothesis Test 1: Determine the level of interest, success, and
ⅲ. Hypothesis Test 2:
ⅳ. 
5. Usability test findings
a. Test participants
ⅰ. N=
ⅱ. Demo info
1. Names
2. Business 
3. Platforms used
4. etc...
b. Findings
ⅰ. Product-Market Fit: Do users want this?
1. Importance of objectives to user
2. Current satisfaction with their process/current solutions (not related to the feature)
ⅱ. Problem-solution fit: If a user were to have this buyer objective, how effective is this tool in helping them solve that objective?
1. Time to complete tasks
2. 
3. Issues
a. Enumerate any ambiguities for the users
b. Measure magnitude of problem
ⅰ. Simple measurement scale
1. Non-critical issue
2. Critical issue
ⅱ. Expanded scale (WIP)
