# Evaluative Research
## How Evaluative Research Goes Wrong
Evaluative research is deceptiveâ€”-it's possible to get positive feedback about an interface while not actually improving your metrics. 
I have seen, when testing an analytics platform, researchers asking which version the participant liked better and getting their opinions (which is not inherently bad). However we don't exactly want to know what they think generally, we care what they do, and we want to see what this interface drives them to do.
Asking "which option do you like more?" Allows the interviewee to select the unit of measure that occurs to them--they might pick the aestetics, the language, the flow, and other factors that are not central to the core value of the feature.

## How to Do Evaluative Research that Drives Outcomes
It's important to define what you want the user to do via that interface then determine if it drives that action.
The inverse, asking people what they think of a screen, allows users to say what they do or don't like. However you want to see if your concept is succesful in helping them acheive the goal(s) you are prioritizing
In order to do this well you should:
+ Ask them what their goals are
+ Confirm those goals overlap with the jobs to be done
+ Determine their experience level. Do they have a clear goal?
+ If not, provide the goal of your interface and ask if that is important to them. For example:
  + "How important is it for you to increase the conversion rate of your sales funnel?" 
  + "Are you aware of the key metrics to do that?"
  + "How well does this interface tell you {key metric 1}? What about {key metric 2}?"
  + "Overall, if this data were presented to you, how confident would you feel you knew what to do to improve your conversion rate?
